---
title: "SVM-TAREA"
author: "María Isabel Chuya"
format: pdf
editor: visual
---


# Tarea SVM

-   Realizar Support Vector Machines con una "Evaluación de Datos en CRUDO" y datos con "Transformación de datos por logaritmo"

## Cargar Librerias

Se cargan las librerias al inicio, puesto que ayuda a que todo el codigo se desarrolle de manera continua.


```{r}
library(ggplot2)
library(e1071)
library(dplyr)
library(reshape2)
library(corrplot)
library(caret)
library(kernlab)
library(pROC)
library(gridExtra)
library(grid)
library(ggfortify)
library(purrr)
library(nnet)
library(ggstatsplot)
library(knitr)
library(lavaan)
library(doParallel) # parallel processing
registerDoParallel()
require(foreach)
require(iterators)
require(parallel)

```


## Cargar Datos

-   Para cargar los datos se establece una variable y se lee los datos cargados en la misma carpeta "read.csv("./cancer.csv"), header=T)"

-   Se usa el comando "head()" para visualizar las primeras filas de un conjunto de datos o un objeto en forma de tabla.

-   Se usa el comando "summary(datos)" para obtener las estadisticas descriptivas de las variables

-   Se usa el comando "str(datos)" para realizar el analisis estadistico de los datos


```{r}
# Cargar los datos
datos <- read.csv("./cancer.csv",header = T)
datos.numericos <- datos[, which(unlist(lapply(datos, is.numeric)))]
colnames(datos.numericos) <- paste0("Var", rep(1:11))

# Explorar los datos
head(datos)  # Ver las primeras filas del conjunto de datos
summary(datos)  # Obtener estadísticas descriptivas de las variables

# Calcular medidas de tendencia central
mean(datos$variable)  # Calcular la media de una variable
median(datos$variable)  # Calcular la mediana de una variable
table(datos$variable)  # Obtener la tabla de frecuencias de una variable categórica

# Calcular medidas de dispersión
sd(datos$variable)  # Calcular la desviación estándar de una variable
range(datos$variable)  # Obtener el rango de una variable

str(datos)
#datos<-datos[,1:11] 

```

```{r}
#head(datos)
```


## Evaluacion de datos en CRUDO

### Diagrama de cajas

Los diagramas de caja, también conocidos como diagramas de caja y bigotes, son gráficos que muestran la distribución de una variable usando cuartiles para que podamos inferir visualmente algunas características sobre su dispersión, ubicación y simetría.

-   Se utiliza el comando "geom_boxplot()" para graficar el diagrama de cajas de todas las variables presentes en los datos de "cancer.csv"


```{r}
#diagrama de cajas unido
datos.melt<-reshape2::melt((datos))
ggplot(datos.melt,aes(y=value,fill=variable))+geom_boxplot()

```


### Grafica de Densidad

Un gráfico de densidad muestra cómo se distribuyen los datos cuantitativos en un rango continuo o período de tiempo. Este gráfico es una adaptación de un histograma que utiliza el suavizado kernel para trazar valores, lo que permite distribuciones más suaves al eliminar el ruido.

-   Se utiliza el comando "geom_density()" para graficar el diagrama de cajas de todas las variables presentes en los datos de "cancer.csv"


```{r}
datos.melt1<-reshape2::melt((datos))
ggplot(datos.melt1,aes(x=value))+geom_density()
```


-   Transformar en función logarítmica porque los algoritmos están diseñados la mayoría por distribuciones normales, aunque el que se está observando funcionaria con todo tipo de datos, sin embargo para corroborar se necesita realizar un análisis de componentes principales.

-   Se transforma a función logarítmica, puesto que la gráfica de densidad no es parecida a una gráfica de distribución normal.

### Analisis de Componentes Principales (PCA) en CRUDO

Una de las técnicas de aprendizaje no supervisado, el análisis de componentes principales (PCA), se usa con frecuencia junto con el análisis exploratorio de datos.

-   Se realiza primero un Scree Plot y seguido se realiza un Biplot para el analisis del comportamiento de los componentes principales.

    -   SCREE PLOT


```{r}
cancer.pca <- prcomp(datos[, 2:11], center=TRUE, scale=TRUE)
plot(cancer.pca, type="l", main='')
grid(nx = 10, ny = 14)
title(main = "PCA", sub = NULL, xlab = "Components")
box()
```


-   

    -   BIPLOT


```{r}
pca_df <- as.data.frame(cancer.pca$x)
ggplot(pca_df, aes(x=PC1, y=PC2, col=datos$diagnostico)) + geom_point(alpha=0.5)
```


### SVM con datos en crudo

1.  Dividir los datos en entrenamiento y prueba


```{r}
n<-nrow(datos)
set.seed(123456)

datos$diagnostico<-as.factor(datos$diagnostico)

train <- sample(n,floor(n*0.7))
datos.train <- datos[train,]
datos.test  <- datos[-train,]


#datos.test <- dato.log[train,]
#datos.test  <- datos.log[-train,]


#set.seed(123456)
#sample <- sample(c(TRUE, FALSE), nrow(datos), replace=TRUE, prob=c(0.7,0.3))
#datos.train  <- datos[sample, ]
#datos.test   <- datos[!sample, ]
```


2.  Formacion de modelos

    Se usa el comando "Kernel" para la formación de modelos.

    -   Se crea para clasifier.lineal y para clasifier.gauss


```{r}
clasifier.lineal<-ksvm(diagnostico~ .,data=datos.train,kernel="vanilladot")
clasifier.gauss<-ksvm(diagnostico~.,data=datos.train,kernel = "rbfdot")
clasifier.lineal
```

```{r}
clasifier.gauss
```


3.  Evaluación de rendimiento del modelo

    Cuando se utiliza "ConfusionMatrix" para resolver un problema de clasificación, donde el resultado puede ser dos o más clases, la matriz de confusión se utiliza como indicador de rendimiento.

    -   Se usa para cada una de los modelos realizados, lineal y de gauss.


```{r}
prediction.linear<-predict(clasifier.lineal,datos.test);res.linear<-table(prediction.linear,datos.test$diagnostico)
prediction.gauss<-predict(clasifier.gauss,datos.test);res.gauss<-table(prediction.gauss,datos.test$diagnostico)
```

```{r}
cmatrix1 <- confusionMatrix(res.linear)
print(cmatrix1)
```

```{r}
cmatrix2<-confusionMatrix(res.gauss)
print(cmatrix2)
```


4.  Validación cruzada quintuple OPCIONAL

La *Validación Cruzada* o *k-fold Cross Validation* consiste en tomar los datos originales y crear a partir de ellos dos conjuntos separados: un primer conjunto de entrenamiento y prueba, y un segundo conjunto de validación.


```{r}
# modelo 5-crossvalidation 
model.5v.linear <- train(diagnostico ~ ., datos.train, method='svmLinear', 
               trControl= trainControl(method='cv', number=5), 
               tuneGrid= NULL, tuneLength=10 ,trace = FALSE)

# plot(model.5v, alpha=0.6)
summary(model.5v.linear)
prediction <- predict(model.5v.linear, datos.test)                           # predict
res.linear.2<-table(prediction, datos.test$diagnostico)                                  # compare

# predict can also return the probability for each class:
cm_nb <- confusionMatrix(res.linear.2)
print(cm_nb)
```

```{r}
# modelo 5-crossvalidation 
model.5v.radial <- train(diagnostico ~ ., datos.train, method='svmRadial', 
               trControl= trainControl(method='cv', number=5), 
               tuneGrid= NULL, tuneLength=10 ,trace = FALSE)

# plot(model.5v, alpha=0.6)
summary(model.5v.radial)
prediction <- predict(model.5v.radial, datos.test)                           # predict
res.radial.2<-table(prediction, datos.test$diagnostico)                                  # compare

# predict can also return the probability for each class:
cm_nb <- confusionMatrix(res.radial.2)
print(cm_nb)
```


### Bootstrap


```{r}
# Por defecto es Bootstrap, con 25 repeticiones para 3 posibles decay
# y 3 posibles sizes
model.bootstrap.linear <- train(diagnostico ~ ., datos.train, method='svmLinear', trace = FALSE) # train
# we also add parameter 'preProc = c("center", "scale"))' at train() for centering and scaling the data

summary(model.bootstrap.linear)
prediction <- predict(model.bootstrap.linear, datos.test)                           # predict
res.gauss.2<-table(prediction, datos.test$diagnostico)                                  # compare

# predict can also return the probability for each class:
# prediction <- predict(model.bootstrap.linear, datos.test, type="prob")  
# head(prediction)
confusionMatrix(res.gauss.2)
```


## Transformación de datos por logaritmo

1.  Transformacion de datos por logaritmo, para una mejor dispersion normal de los mismos.

-   CADA PICO SIGNIFICA A DISTRIBUCIÓN DE UNA TEXTURA DE LA IMAGEN.


```{r frag2, echo=TRUE,message=FALSE,warning=FALSE,fig.align='center',fig.height=4}

clases<-as.factor(datos[,ncol(datos)])
X<-datos[,-ncol(datos)][,-1]
X.melt<-melt((log2(X+0.5)))
p <- ggplot(aes(x=value,colour=variable), data=X.melt)
p + geom_density(show.legend = F)
```


-   Definimos como variable "X.log" a los nuevos datos tranformados mediante logaritmos.


```{r}
clases <- as.factor(datos[,ncol(datos)])

X.log<-log2(X+0.5)
datos.log<-cbind(X+0.5,clases)
class(datos.log)
```


### Analisis de Componentes Principales (PCA) con los datos tranformados logaritmicos

Una de las técnicas de aprendizaje no supervisado, el análisis de componentes principales (PCA), se usa con frecuencia junto con el análisis exploratorio de datos.

-   Se realiza primero un Scree Plot y seguido se realiza un Biplot para el analisis del comportamiento de los componentes principales.

    -   SCREE PLOT


```{r}
cancer.pca1 <- prcomp(X.log[, 2:11], center=TRUE, scale=TRUE)
plot(cancer.pca1, type="l", main='')
grid(nx = 10, ny = 14)
title(main = "PCA", sub = NULL, xlab = "Components")
box()
```


-   

    -   BIPLOT


```{r}
pca_df1 <- as.data.frame(cancer.pca1$x)
ggplot(pca_df1, aes(x=PC1, y=PC2, col=datos$diagnostico)) + geom_point(alpha=0.5)


#pca_df1$color <- datos$diagnostico
#ggplot(pca_df1, aes(x=PC1, y=PC2,color=color)) + geom_point(alpha=0.5)
```


-   Si comparamos con la gráfica anterior, podemos observar unos ligeros cambios en ambas graficas, sin embargo, en la gráfica del Biplot se observa que se ha invertido la grafica a comparación de los datos trabajados en curdo. Pero esta transformación ha permitido observar de mejor manera el comportamiento y dispersión normal de los datos.

### SVM con datos con transformacion logaritmica

1.  Dividir los datos en entrenamiento y prueba


```{r}
n1<-nrow(X.log)
set.seed(123456)


train <- sample(n1,floor(n1*0.7))
datos.train1 <- datos.log[train,]
datos.test1  <- datos.log[-train,]
```


2.  Formación de modelos

    Se usa el comando "Kernel" para la formación de modelos.

    -   Se crea para clasifier.lineal y para clasifier.gauss


```{r}
clasifier.linealt<-ksvm(clases~ .,data=datos.train1,kernel="vanilladot")
clasifier.gausst<-ksvm(clases~.,data=datos.train1,kernel = "rbfdot")
clasifier.linealt
```

```{r}
clasifier.gausst
```


3.  Evaluación de rendimiento del modelo

Cuando se utiliza "ConfusionMatrix" para resolver un problema de clasificación, donde el resultado puede ser dos o más clases, la matriz de confusión se utiliza como indicador de rendimiento.

Se usa para cada una de los modelos realizados, lineal y de gauss.


```{r}
prediction.lineart<-predict(clasifier.linealt,datos.test1);res.lineart<-table(prediction.lineart,datos.test1$clases)
prediction.gausst<-predict(clasifier.gausst,datos.test1);res.gausst<-table(prediction.gausst,datos.test1$clases)
```

```{r}
(cmatrix1T<-confusionMatrix(res.lineart,positive = "t"))
#cmatrix1T<-confusionMatrix(res.lineart)
#cmatrix1T

```

```{r}
(cmatrix2T<-confusionMatrix(res.gausst,positive = "t"))
```


4.  Validación cruzada quintuple OPCIONAL

La *Validación Cruzada* o *k-fold Cross Validation* consiste en tomar los datos originales y crear a partir de ellos dos conjuntos separados: un primer conjunto de entrenamiento y prueba, y un segundo conjunto de validación.


```{r}
# modelo 5-crossvalidation 
model.5v.linear1 <- train(clases~ ., datos.train1, method='svmLinear', 
               trControl= trainControl(method='cv', number=5), 
               tuneGrid= NULL, tuneLength=10 ,trace = FALSE)

# plot(model.5v, alpha=0.6)
summary(model.5v.linear1)
prediction1 <- predict(model.5v.linear1, datos.test1)                           # predict
res.linear.21<-table(prediction1, datos.test1$clases)                                  # compare

# predict can also return the probability for each class:
cm_nb <- confusionMatrix(res.linear.21)
print(cm_nb)
```

```{r}
# modelo 5-crossvalidation 
model.5v.radial1 <- train(diagnostico ~ ., datos.train1, method='svmRadial', 
               trControl= trainControl(method='cv', number=5), 
               tuneGrid= NULL, tuneLength=10 ,trace = FALSE)

# plot(model.5v, alpha=0.6)
summary(model.5v.radial1)
prediction1 <- predict(model.5v.radial1, datos.test1)                           # predict
res.radial.21<-table(prediction1, datos.test1$clases)                                  # compare

# predict can also return the probability for each class:
cm_nb <- confusionMatrix(res.radial.21)
print(cm_nb)
```


### Bootstrap


```{r}
# Por defecto es Bootstrap, con 25 repeticiones para 3 posibles decay
# y 3 posibles sizes
model.bootstrap.linear1 <- train(clases ~ ., datos.train1, method='svmLinear', trace = FALSE) # train
# we also add parameter 'preProc = c("center", "scale"))' at train() for centering and scaling the data

summary(model.bootstrap.linear1)
prediction <- predict(model.bootstrap.linear, datos.test1)                           # predict
res.gauss.21<-table(prediction, datos.test1$clases)                                  # compare

# predict can also return the probability for each class:
# prediction <- predict(model.bootstrap.linear, datos.test, type="prob")  
# head(prediction)
confusionMatrix(res.gauss.21)
```

