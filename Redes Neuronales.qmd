---
title: "Redes neuronales Tarea"
author: "María Isabel Chuya-Nataly Quintanilla"
format: pdf
editor: visual
---

# Tarea REDES NEURONALES

1\. Descripción de los mismos numérica y gráficamente

2\. Entender las fortalezas y debilidades del ANN perceptrón

4\. Saber qué son las funciones de activación

5\. Realizar un modelo preliminar de una capa sobre la clasificacion begnigno o maligno

6\. Mejorar el modelo

7\. Comparación de resultados mediante una matriz de confusión

## Fortalezas y debilidades del ANN perceptrón

### Fortalezas: 

1.  Capacidad de aprendizaje no lineal: un perceptrón de ANN puede aprender y representar funciones no lineales, a diferencia de un perceptrón simple. Un perceptrón en un ANN puede capturar relaciones más complejas entre las características de entrada y las salidas deseadas al agregar capas ocultas con funciones de activación no lineales, como la función sigmoide o ReLU.
2.  Mayor capacidad de representación: En comparación con un perceptrón simple, un perceptrón en un ANN tiene una mayor capacidad de representación debido a su estructura multicapa y las conexiones entre capas. Puede aprender las características abstractas y las representaciones jerárquicas de los datos, lo que lo hace adecuado para abordar problemas más complejos y tareas de aprendizaje más difíciles.
3.  Aprendizaje con retroalimentación: la retropropagación del error, un algoritmo efectivo para ajustar los pesos y sesgos de la red neuronal, permite que los perceptrones de una red neuronal aprendan. La retroalimentación del error ayuda a la red a aprender de sus errores y mejorar su rendimiento con el tiempo.

### Debilidades: 

1.  La complejidad computacional aumenta significativamente a medida que se agregan capas y conexiones en un ANN. Esto implica que, en comparación con un perceptrón simple, el entrenamiento y la predicción pueden requerir más tiempo y recursos computacionales.
2.  Posibles sobreajustes: Cuando los ANN se entrenan con conjuntos de datos pequeños o ruidosos, es posible que se sobreajusten. En lugar de generalizar patrones más amplios, la red puede memorizar los datos de entrenamiento. Se necesitan métodos de regularización, como reducir la tasa de aprendizaje o incluir términos de regularización.
3.  Dificultades de interpretación: La complejidad de ANN puede dificultar la comprensión del proceso de toma de decisiones de la red. La interpretación de los resultados de un ANN puede ser más difícil en comparación con modelos más simples y lineales debido a la naturaleza de la representación distribuida y las conexiones no lineales.
4.  Mayor necesidad de datos de entrenamiento: Para que las ANNs funcionen correctamente, especialmente las con múltiples capas, pueden requerir una cantidad significativa de datos de entrenamiento. El ANN puede no poder comprender adecuadamente la complejidad del problema y sufrir de baja generalización si tiene pocos datos de entrenamiento.

## Funciones de Activación 

Las funciones de activación de las redes neuronales se aplican a la salida de una neurona o unidad de procesamiento de una red neuronal. Estas características permiten que las redes neuronales capturen patrones y relaciones más complejos en los datos y introducen la no linealidad en la red.

Las funciones de activación se aplican a todas las entradas de una neurona, incluido el sesgo, y producen una salida que se transmite a las neuronas de la siguiente capa. Dado que permiten que la salida de una neurona no sea simplemente una combinación lineal de entradas, estas funciones introducen no linealidad en la red.

## Cargar Librerias

Se cargan las librerias al inicio, puesto que ayuda a que todo el codigo se desarrolle de manera continua.

```{r}
library(ggplot2)
library(e1071)
library(dplyr)
library(reshape2)
library(corrplot)
library(caret)
library(kernlab)
library(pROC)
library(gridExtra)
library(grid)
library(ggfortify)
library(purrr)
library(nnet)
library(ggstatsplot)
library(knitr)
library(lavaan)
library(doParallel) # parallel processing
registerDoParallel()
require(foreach)
require(iterators)
require(parallel)
library(tidymodels)
library(tidyverse)
library(ggthemes)
library(skimr)
library(DataExplorer)
library(ggpubr)
library(mosaicData)
library(h2o)
library(neuralnet)
library(NeuralNetTools)
```

## Cargar Datos

-   Para cargar los datos se establece una variable y se lee los datos cargados en la misma carpeta "read.csv("./wdbc.data"), header=T)"

-   Se usa el comando "head()" para visualizar las primeras filas de un conjunto de datos o un objeto en forma de tabla.

-   Se usa el comando "summary(datos)" para obtener las estadisticas descriptivas de las variables

-   Se usa el comando "str(datos)" para realizar el analisis estadistico de los datos

```{r}
# Cargar los datos
datos <- read.csv("./wdbc.data",header = T) 
datos.numericos <- datos[, which(unlist(lapply(datos, is.numeric)))]
colnames(datos.numericos) <- paste0("Var", rep(1:10))
datos<-datos[,1:10] 
colnames(datos) <- c("ID_number", "Diagnosis", "radius1", "texture1",
                     "perimeter1", "area1","smoothness1", "compactness1", 
                     "concavity1", "concave_points1")

# Explorar los datos
head(datos)  # Ver las primeras filas del conjunto de datos
summary(datos)  # Obtener estadísticas descriptivas de las variables

str(datos)


```

## Descripcion numérica y gráfica

```{r}
#Tabla de resusmen de datos 
skim(datos)
```

```{r}
# Número de datos ausentes por variable
# ==============================================================================
datos %>% map_dbl(.f = function(x){sum(is.na(x))})
```

```{r}
plot_missing(
  data    = datos, 
  title   = "Porcentaje de valores ausentes",
  ggtheme = theme_bw(),
  theme_config = list(legend.position = "none")
)

```

```{r}
#diagrama de cajas unido
datos.melt<-reshape2::melt((datos))
ggplot(datos.melt,aes(y=value,fill=variable))+geom_boxplot()

#grafica de densidad
datos.melt<-reshape2::melt((datos))
ggplot(datos.melt,aes(x=value))+geom_density()

#csa<- as.data.frame(datos.test)

```

```{r}
#PCA
cancer.pca <- prcomp(datos.numericos[, 1:10], center=TRUE, scale=TRUE)
plot(cancer.pca, type="l", main='')
grid(nx = 10, ny = 14)
title(main = "PCA", sub = NULL, xlab = "Components")
box()

pca_df <- as.data.frame(cancer.pca$x)
ggplot(pca_df, aes(x=PC1, y=PC2, col=datos$Diagnosis)) + geom_point(alpha=0.5)
```

```{r}
# Gráfico de distribución para cada variable numérica
# ==============================================================================
datos1<- datos[,-2]
plot_density(
  data    = datos %>% select(-ID_number),
  ncol    = 3,
  title   = "Distribución variables continuas",
  ggtheme = theme_bw(),
  theme_config = list(
                  plot.title = element_text(size = 14, face = "bold"),
                  strip.text = element_text(colour = "black", size = 12, face = 2)
                 )
  )
```

```{r}
# Reparto de datos en train y test
# ==============================================================================
n<-nrow(datos)
set.seed(123456)

datos$Diagnosis<-as.factor(datos$Diagnosis)

train <- sample(n,floor(n*0.7))
datos.train <- datos[train,]
datos.test  <- datos[-train,]

csa<- as.data.frame(datos.test)
```

```{r}
# Se almacenan en un objeto `recipe` todos los pasos de preprocesado y, finalmente,
# se aplican a los datos.
transformer <- recipe(
                  formula = ID_number ~ .,
                  data =  datos.train
               ) %>%
               step_naomit(all_predictors()) %>%
               step_nzv(all_predictors()) %>%
               step_center(all_numeric(), -all_outcomes()) %>%
               step_scale(all_numeric(), -all_outcomes()) %>%
               step_dummy(all_nominal(), -all_outcomes())

transformer
```

```{r}
# Se entrena el objeto recipe
transformer_fit <- prep(transformer)

# Se aplican las transformaciones al conjunto de entrenamiento y de test
datos_train_prep <- bake(transformer_fit, new_data = datos.train)
datos_test_prep  <- bake(transformer_fit, new_data = datos.test)

glimpse(datos_train_prep)
```

```{r}
# Inicialización del cluster
# ==============================================================================
h2o.init(
  nthreads = -1,
  max_mem_size = "4g"
)


```

```{r}
# Se eliminan los datos del cluster por si ya había sido iniciado.
h2o.removeAll()
h2o.no_progress()
```

```{r}
datos_train  <- as.h2o(datos_train_prep, key = "datos.train")
datos_test   <- as.h2o(datos_test_prep, key = "datos.test")
# Espacio de búsqueda de cada hiperparámetro
# ==============================================================================
hiperparametros <- list(
                      epochs = c(50, 100, 500),
                      hidden = list(5, 10, 25, 50, c(10, 10))
                    )


# Búsqueda por validación cruzada
# ==============================================================================
variable_respuesta <- 'radius1'
predictores <- setdiff(colnames(datos_train), variable_respuesta)

grid <- h2o.grid(
              algorithm    = "deeplearning",
              activation   = "Rectifier",
              x            = predictores,
              y            = variable_respuesta,
              training_frame = datos_train,
              nfolds       = 3, #validacion cruzada
              standardize  = FALSE,
              hyper_params = hiperparametros,
              search_criteria = list(strategy = "Cartesian"),
              seed         = 123456,
              grid_id      = "grid"
          )
# Resultados del grid
# ==============================================================================
resultados_grid <- h2o.getGrid(
                     sort_by = 'rmse',
                     grid_id = "grid",
                     decreasing = FALSE
                   )
data.frame(resultados_grid@summary_table)
# Mejor modelo encontrado
# ==============================================================================
modelo_final <- h2o.getModel(resultados_grid@model_ids[[1]])

```

```{r}
predicciones <- h2o.predict(
                  object  = modelo_final,
                  newdata = datos_test
                )

predicciones <- predicciones %>%
                as_tibble() %>%
                mutate(valor_real = as.vector(datos_test$Diagnosis))

predicciones %>% head(10)
rmse(predicciones, truth = valor_real, estimate = predict, na_rm = TRUE)





```

## Figura percepción ANN

```{r}
modelLookup("nnet")
tuneGrid <- expand.grid(size = 2*1:5, decay = c(0, 0.001, 0.01))

set.seed(123456)
caret.nnet <- train(ID_number ~ ., data = datos.train, method = "nnet",
             preProc = c("range"), # Reescalado en [0,1]
             tuneGrid = tuneGrid,
             trControl = trainControl(method = "cv", number = 10), 
             linout = TRUE, maxit = 200, trace = FALSE)

ggplot(caret.nnet, highlight = TRUE)
plotnet(caret.nnet$finalModel)
```

```{r}
pred <- predict(caret.nnet, newdata = datos.test)
obs <- datos.test$ID_number

plot(pred, obs, main = "Observado frente a predicciones",
     xlab = "Predicción", ylab = "Observado")
abline(a = 0, b = 1)
```

```{r}
accuracy <- function(pred, obs, na.rm = FALSE,
                     tol = sqrt(.Machine$double.eps)) {
  err <- obs - pred     # Errores
  if(na.rm) {
    is.a <- !is.na(err)
    err <- err[is.a]
    obs <- obs[is.a]
  }
  perr <- 100*err/pmax(obs, tol)  # Errores porcentuales
  return(c(
    me = mean(err),           # Error medio
    rmse = sqrt(mean(err^2)), # Raíz del error cuadrático medio
    mae = mean(abs(err)),     # Error absoluto medio
    mpe = mean(perr),         # Error porcentual medio
    mape = mean(abs(perr)),   # Error porcentual absoluto medio
    r.squared = 1 - sum(err^2)/sum((obs - mean(obs))^2) # Pseudo R-cuadrado
  ))
}

accuracy(pred, obs)

```
